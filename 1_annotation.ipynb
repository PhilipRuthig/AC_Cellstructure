{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hoellenmaschine2\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: Philip Ruthig, PhD Student at Leipzig University & MPI for Cognitive and Brain Sciences.\n",
    "This script 3d tiff files as input and annotates round structures in them (e.g. cell centres, cell nuclei).\n",
    "Afterward, a spatial cell center distribution is calculated and the results are saved.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "import scipy.signal as sig\n",
    "import math as m\n",
    "from skimage.feature import peak_local_max\n",
    "import skimage.morphology as morph\n",
    "import tifffile as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaborkernel(edge_length,sigma, freq, phase, radius, z_scale_factor):\n",
    "    '''\n",
    "    Returns two gabor kernels (real and imaginary) for spheroid detection. Can be convolved with an image (using scipy.signal.fftconvolve)\n",
    "    \n",
    "    edge_length: edge length of the kernel array\n",
    "    sigma: sigma of gaussian part of the gabor kernel\n",
    "    freq: frequency of the complex plane wave\n",
    "    phase: phase displacement in pixels\n",
    "    radius: radius of how much the gaussian wave is displaced from the origin\n",
    "    z_scale_factor: factor of how much z axis is compressed. 1 for isotropic data\n",
    "    '''\n",
    "    if edge_length%2==0:\n",
    "        edge_length = edge_length+1\n",
    "    \n",
    "    size_z=np.arange(0,edge_length,1)\n",
    "    size_y=np.arange(0,edge_length,1)\n",
    "    size_x=np.arange(0,edge_length,1)\n",
    "    \n",
    "    z,y,x = np.meshgrid(size_z, size_y, size_x)\n",
    "    z,y,x = z-(len(size_z)//2),y-(len(size_y)//2),x-(len(size_x)//2)\n",
    "    y = y*z_scale_factor\n",
    "    \n",
    "    A = (2*m.pi*sigma**2)\n",
    "    r = np.sqrt(np.power(z,2) + np. power(y,2) + np.power(x,2))\n",
    "    \n",
    "    kernel_real = (1/A)*np.exp(-1*m.pi*((np.power((r-radius),2))/sigma**2)) * (np.cos((freq*(r-radius)*2*m.pi+phase)))\n",
    "    kernel_imag = (1/A)*np.exp(-1*m.pi*((np.power((r-radius),2))/sigma**2)) * (np.sin((freq*(r-radius)*2*m.pi+phase)))\n",
    "            \n",
    "    #inverting kernels\n",
    "    kernel_real = kernel_real*(-1)\n",
    "    kernel_imag = kernel_imag*(-1)\n",
    "        \n",
    "    return kernel_real, kernel_imag\n",
    "\n",
    "def cell_centre_distribution(bool_input,reach,sparsity_factor=1):\n",
    "    '''\n",
    "    Computes a mean distribution of cells in a given boolean array in a given edge length cube. Cycles through all TRUE pixels\n",
    "    and checks the surroundings in a cube with the edge length \"reach\".\n",
    "\n",
    "    bool_input: boolean numpy array input\n",
    "    reach: edge length of the cube\n",
    "    sparsity_factor: subsampling factor. 1 means every cell, 10 every 10th cell\n",
    "    '''\n",
    "\n",
    "    struct = np.zeros((3,3,3))\n",
    "    struct[1,1,1] = 1\n",
    "    \n",
    "    centres_labeled, n_cells_labeled = ndi.label(bool_input, structure=struct)\n",
    "\n",
    "    invalid_area_mask = np.ones_like(bool_input,dtype=\"bool\") #define valid part of data - exclude outer rim\n",
    "    invalid_area_mask[0:reach//2,:,:] = False\n",
    "    invalid_area_mask[-reach//2:,:,:] = False\n",
    "    invalid_area_mask[:,-reach//2:,:] = False\n",
    "    invalid_area_mask[:,0:reach//2,:] = False\n",
    "    invalid_area_mask[:,:,-reach//2:] = False\n",
    "    invalid_area_mask[:,:,0:reach//2] = False\n",
    "    \n",
    "    for i in range(0,n_cells_labeled,sparsity_factor): #iterate over all cells\n",
    "        if i == 0: #initialize analysis\n",
    "            resultarray = np.zeros((reach,reach,reach)) #initialize results array\n",
    "            n_valid_cells = 0\n",
    "            n_invalid_cells = 0\n",
    "            continue\n",
    "\n",
    "        clocz,clocy,clocx = np.nonzero(centres_labeled==i) #get active cell coordinates\n",
    "            \n",
    "        if invalid_area_mask[clocz[0],clocy[0],clocx[0]]==True:\n",
    "            n_valid_cells += 1\n",
    "            tmpdata = bool_input[clocz[0]-reach//2:clocz[0]+reach//2,clocy[0]-reach//2:clocy[0]+reach//2,clocx[0]-reach//2:clocx[0]+reach//2]\n",
    "        else:\n",
    "            n_invalid_cells += 1\n",
    "            continue\n",
    "        \n",
    "        resultarray = resultarray + tmpdata #add tmp data to complete results array\n",
    "        \n",
    "    resultarray[reach//2,reach//2,reach//2] = 0 #delete reference cell\n",
    "    return resultarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tuple of image names to be processed\n",
    "img_paths = (\n",
    "r\"data_from_bioimg_arx\\PR008_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR008_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR008_R.tif\",\n",
    "r\"data_from_bioimg_arx\\PR009_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR009_R.tif\",\n",
    "r\"data_from_bioimg_arx\\PR010_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR010_R.tif\",\n",
    "r\"data_from_bioimg_arx\\PR012_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR012_R.tif\",\n",
    "r\"data_from_bioimg_arx\\PR013_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR013_R.tif\",\n",
    "r\"data_from_bioimg_arx\\PR014_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR014_R.tif\",\n",
    "r\"data_from_bioimg_arx\\PR001_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR001_R.tif\",\n",
    "r\"data_from_bioimg_arx\\PR003_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR003_R.tif\",\n",
    "r\"data_from_bioimg_arx\\PR005_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR005_R.tif\",\n",
    "r\"data_from_bioimg_arx\\PR006_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR006_R.tif\",\n",
    "r\"data_from_bioimg_arx\\PR007_L.tif\",\n",
    "r\"data_from_bioimg_arx\\PR007_R.tif\",)\n",
    "\n",
    "save_path     = r\"processed\\\\\"  #path to results folder\n",
    "\n",
    "### variables that will need tweaking depending on the image being processed\n",
    "gauss_sigma   = 0.7   #sigma for gaussian blurred image\n",
    "\n",
    "### gabor filter variables. need to be adapted to cell size, data & quality\n",
    "hucd_edge          = 40   #gabor kernel edge length (x=y=z)\n",
    "hucd_gabor_freq    = 1/10 #frequency of wave component\n",
    "hucd_gabor_phase   = 3.7  #wave component offset\n",
    "hucd_gabor_sigma   = 8   #gaussian deviation #7\n",
    "hucd_gabor_radius  = 9    #donut radius       #10  \n",
    "hucd_z_factor      = 7  #factor of how much the z axis is compressed in microscopy data. 1 for isotropic data\n",
    "hucd_tissue_thresh = 250  #intensity threshold to check cells are in tissue\n",
    "hucd_r_maxima      = 6    #radius of footprint for detecting local maxima in the gabor filtered image #6\n",
    "hucd_min_distance  = 4    #min distance between local maxima #4\n",
    "\n",
    "### data analysis variables\n",
    "reach = 100 #number of surrounding pixels taken into account for cell distribution analysis\n",
    "sparsity_factor = 50 #subsampling for cell distribution analysis\n",
    "\n",
    "### initializing variables and structuring elements\n",
    "footprint_maxima = morph.ball(6)   # structuring element for detecting local maxima in gabor annulus filtered image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hoellenmaschine2\\AppData\\Local\\Temp\\ipykernel_12476\\2382627510.py:8: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  hucd_img = ndi.filters.gaussian_filter(hucd_img, sigma=gauss_sigma)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measuring maxima\n"
     ]
    }
   ],
   "source": [
    "for img_path in img_paths:\n",
    "    # open image\n",
    "    img_file=tf.imread(img_path)\n",
    "    img_shape = img_file.shape\n",
    "    hucd_img = img_file[:,1,:,:]\n",
    "\n",
    "    # apply gaussian\n",
    "    hucd_img = ndi.filters.gaussian_filter(hucd_img, sigma=gauss_sigma)\n",
    "\n",
    "    # creating filter kernel\n",
    "    hucd_gabor_kernel_real, hucd_gabor_kernel_imag = gaborkernel(\n",
    "                                                        edge_length=hucd_edge,\n",
    "                                                        sigma=hucd_gabor_sigma,\n",
    "                                                        freq=hucd_gabor_freq,\n",
    "                                                        radius=hucd_gabor_radius,\n",
    "                                                        z_scale_factor=hucd_z_factor,\n",
    "                                                        phase=hucd_gabor_phase\n",
    "                                                        )\n",
    "    \n",
    "    # applying gabor filter\n",
    "    hucd_gaborimg_real = sig.fftconvolve(hucd_img, hucd_gabor_kernel_real, mode=\"same\")\n",
    "\n",
    "    print(\"measuring maxima\")\n",
    "\n",
    "    # measure maxima\n",
    "    hucd_centers = peak_local_max(\n",
    "                            image=hucd_gaborimg_real,\n",
    "                            min_distance=hucd_min_distance,\n",
    "                            # indices=False,\n",
    "                            footprint=footprint_maxima,\n",
    "                            exclude_border=0,\n",
    "                            )\n",
    "\n",
    "    print(\"puttig maxima into images\")\n",
    "\n",
    "    # put maxima into image\n",
    "    hucd_centers_3d = np.zeros_like(hucd_gaborimg_real,dtype='bool')\n",
    "\n",
    "    for id in hucd_centers:\n",
    "        hucd_centers_3d[id[0],id[1],id[2]]=True\n",
    "\n",
    "\n",
    "    # threshold centers according to tissue background intensity\n",
    "    hucd_centers_3d[hucd_img<hucd_tissue_thresh]=0\n",
    "\n",
    "    print(\"saving images\")\n",
    "    # save as bool\n",
    "    tf.imwrite(save_path + img_path[21:28] + r\"_hucd_centers.tif\",hucd_centers_3d)\n",
    "\n",
    "    print(\"do cell centre analysis\")\n",
    "\n",
    "    # do cell centre analysis\n",
    "    hucd_resultarray = cell_centre_distribution(bool_input=hucd_centers_3d,reach=reach, sparsity_factor=sparsity_factor)\n",
    "\n",
    "    print(\"save resultarray\")\n",
    "\n",
    "    # save resultarray as well\n",
    "    tf.imwrite(save_path + img_path[21:28] + r\"_hucd_center_dist.tif\",hucd_resultarray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
